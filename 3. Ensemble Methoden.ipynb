{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"left\">\n",
    "  <img style=\"float: right;\" src=\"./imgs/logo1.png\" width=\"100\" />\n",
    "  <img style=\"float: left;\" src=\"./imgs/ipa.png\" width=\"300\" /> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/div.png\" width=\"100%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# 3. Ensemble Methoden\n",
    "3.1 Einführung: Regression mit Standard <span style=\"color:#179c80\"><b>Single-layer Perceptron</b></span><br>\n",
    "3.2 <span style=\"color:#179c80\"><b>Training</b></span> eines Modells <br> \n",
    "3.3 Bauen eines <span style=\"color:#179c80\"><b>Ensembles</b></span><br> \n",
    "\n",
    "\n",
    "## 3.1 Einführung: Regression mit Standard Single-layer Perceptron\n",
    "\n",
    "Neben der Einführung in das Schätzen von Verteilungen mit MCMC und Variational Inference, wollen wir nun mithilfe eines <span style=\"color:#179c80\"><b>Neuronalen Netzes</b></span> eine klassische eindimensionale <span style=\"color:#db8642\">Regressions</span>-Aufgabe lösen. Die Besonderheit besteht darin, dass wir zusätzlich zur <span style=\"color:#179c80\"><b>Funktionsschätzung</b></span> das Neuronale Netz für eine <span style=\"color:#179c80\"><b>Unsicherheitsangabe</b></span> der entsprechenden Vorhersage nutzen möchten. Wir werden hierfür einen sehr <span style=\"color:#179c80\"><b>intuitiven</b></span> Ansatz umsetzen, bei welchem wir <span style=\"color:#179c80\"><b>mehrere</b></span> Netzwerke <span style=\"color:#db8642\">separat</span> trainieren und deren Vorhersage <span style=\"color:#db8642\">zusammenführen</span>. Diese Methode <span style=\"color:#db8642\">beruht</span> auf der Tatsache, dass sich die Vorhersagen der Modelle für Bereiche mit vielen Daten <span style=\"color:#db8642\">ähneln</span> werden, jedoch für Bereiche ohne Daten <span style=\"color:#db8642\">abweichen</span>.\n",
    "\n",
    "<br>\n",
    "Im einzelnen soll es um die Modellierung der kubischen Funktion $x^3$ gehen. Hierfür erstellen wir <span style=\"color:#db8642\">leicht verrauschte</span> Trainingsdaten für einen bestimmten Funktionsbereich, wobei die Datendichte nach außen <span style=\"color:#db8642\">abnimmt</span>:\n",
    "<img src=\"./imgs/ense.png\" width=600>\n",
    "\n",
    "<br>\n",
    "Zunächst wählen wir ein klassisches Vorgehen für die Umsetzung der Regression, indem wir nur ein Neuronales Netz trainieren. Für die beschriebene Aufgabe genügt hierfür ein Modell mit nur <span style=\"color:#db8642\">einer</span> Schicht. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"  style=\"border-color:white\">\n",
    "    <b>Aufgabe</b>: Nutzen Sie das <em>PyTorch</em> Framework und vervollständigen Sie die nachfolgende <em>Single-Layer Perceptron</em> (SLP) Klasse. \n",
    "    <ul>\n",
    "        <li>Ziel der <em>__init__</em> Methode ist die Erstellung eines Neuronalen Netzes mit folgenden Schichten bzw. Aktivierungsfunktionen: <em>lineare</em> Schicht, <em>ReLU</em>, <em>lineare</em> Ausgabeschicht. Verwenden Sie die <em>Sequential</em> Klasse und weißen Sie die Schichten dem Attribut <em> self.model </em> zu.</li>\n",
    "        <li>Ziel der <em> forward </em> Methode ist die Verarbeitung und Berechnung der Modellausgabe für eine gegebene Eingabe.\n",
    "    </ul>\n",
    "<br>Ihre Umsetzung können Sie mit darauffolgender Zelle testen.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-warning\" style=\"background-color:#f2decc\n",
    ";border-color:white\">\n",
    "    <b>Hilfreiche Funktionen</b>: \n",
    "    <ul>\n",
    "        <li> <em>model=nn.Sequential(...)</em>: Erlaubt die Erstellung eines Modells durch die dem Konstruktor übergebenen Module. Automatisch werden dann über <em>model(x)</em> die Layer-Ausgaben berechnet</li>\n",
    "    <li> <em>nn.Linear(input_dim, output_dim)</em>: Fully-connected Schicht</li>\n",
    "       <li> <em>nn.ReLU()</em></li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\" style=\"border-color:white\">\n",
    "    <b>Wichtig!</b>: Bei Änderungen der <em>SLP</em> Klasse, führen sie die entsprechende Zelle neu aus. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports [Keine Änderung notwendig]\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from helper.aux_function import create_data, get_toggle_value\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from helper.plots import *\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets\n",
    "from ipywidgets import HBox, VBox, RadioButtons, Layout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from scipy.stats import beta, binom, norm\n",
    "import numpy as np\n",
    "from ipywidgets import *\n",
    "from helper.debounce import debounce\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "import math\n",
    "import jdc\n",
    "import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SLP(nn.Module):\n",
    "  def __init__(self, hidden=50, input_dim=1, output_dim=1):\n",
    "    super().__init__()\n",
    "    \n",
    "    #self.model = ...\n",
    "\n",
    "  def forward(self, x):\n",
    "    return -1 # Geben Sie den richtigen Wert zurück"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test: muss 0.993 ergeben\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "print('%.3f' % SLP().forward(torch.Tensor([5.]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### <div class=\"alert alert-block alert-success\" style=\"background-color:#b6dad2;color:#179c80;border-color:white\"> <b>Lösung</b> <small style=\"color:#179c80\">(Klicken auf den Pfeil um die Lösung aufzuklappen)</small></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class SLP(nn.Module):\n",
    "  def __init__(self, hidden=50, input_dim=1, output_dim=1):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden, output_dim)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "<img src=\"./imgs/div.png\" width=\"100%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## 3.2 Training eines Modells\n",
    "Für das Training unseres Modells mit Daten muss zunächst der Modellfehler bestimmt werden. Da eine Regression vorliegt, bietet sich der <span style=\"color:#179c80\"><b>Mean-Squared Error</b></span> (MSE) als Fehlerfunktion an. Ist dieser basierend auf den Trainingsdaten berechnet, lassen sich die entsprechenden Gradienten ableiten und wir können den <span style=\"color:#179c80\"><b>Adam</b></span> Optimizer nutzen, um unsere Modellparameter in Richtung des <span style=\"color:#db8642\">steilsten</span> Abstiegs der Fehlerfunktion zu aktualisieren.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"  style=\"border-color:white\">\n",
    "    <b>Aufgabe</b>: Setzen Sie das Training für ein standard Neuronales Netz in der nachfolgenden Methode um. Hierfür sind folgende Aufgaben zu erledigen:\n",
    "    <ul>\n",
    "        <li>Definieren Sie den <em>MSE</em> als <em>Fehlerfunktion</em> (<em>loss_function</em>).</li>\n",
    "        <li>Erstellen Sie den <em>Optimizer</em> und übergeben Sie die Parameter unseres SLPs (<em>self.model</em>) als erstes Argument. Als zweites Argument ist <em>lr=0.1</em> zu setzen. </li>\n",
    "        <li>In jeder Epoche:\n",
    "            <ul> <li>Berechnen Sie die Modellvorhersage für alle Trainingsdaten (Da wir später auch nur sehr wenig Daten verwenden (100), ist keine Aufteilung der Trainingsdaten in Batches notwendig).</li>\n",
    "                <li>Berechnen Sie den Modellfehler.</li>\n",
    "                <li>Zurücksetzen aller Gradienten auf Null.</li>\n",
    "                <li>Berechnung neuer Gradienten.</li>\n",
    "                <li>Ausführen eines Optimierungsschrittes.</li>\n",
    "    </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-warning\" style=\"background-color:#f2decc\n",
    ";border-color:white\">\n",
    "    <b>Hilfreiche Funktionen</b>: \n",
    "    <ul>\n",
    "        <li> <em>loss_function=nn.MSELoss()</em>: Nach Definition kann dann über <em>loss_function(input, target)</em> der Modellfehler berechnet werden, wobei <em>input</em> der Modellvorhersage entspricht.</li>\n",
    "    <li> <em>torch.optim.Adam(params, lr)</em></li>\n",
    "       <li> <em>optimizer.zero_grad() </em>: Nullt alle Gradient vor der Berechnung neuer Gradienten. </li>\n",
    "        <li> <em>loss.backward() </em>: Berechnung von Gradienten. </li>\n",
    "        <li> <em>optimizer.step() </em>: Ausführen eines Optimierungsschrittes. </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\" style=\"border-color:white\">\n",
    "    <b>Wichtig!</b>: Bei Änderungen der <em>SLP</em> Klasse, führen sie die entsprechende Zelle neu aus. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SLP\n",
    "def train(self, X_train, y_train, epochs):\n",
    "\n",
    "    #loss_function = ...\n",
    "    #optimizer = ...\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        #pred = ...\n",
    "        #loss = ...\n",
    "        #optimizer. ...\n",
    "        #loss. ...\n",
    "        #optimizer. ...\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test: muss -4.140 ergeben\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(0)\n",
    "model = SLP()\n",
    "model.train(torch.randn(20, 1), torch.randn(20, 1), epochs=1)\n",
    "print('%.3f' % model.forward(torch.Tensor([5.]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### <div class=\"alert alert-block alert-success\" style=\"background-color:#b6dad2;color:#179c80;border-color:white\"> <b>Lösung</b> <small style=\"color:#179c80\">(Klicken auf den Pfeil um die Lösung aufzuklappen)</small></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%%add_to SLP\n",
    "def train(self, X_train, y_train, epochs):\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(self.model.parameters(), lr=0.1)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        pred = self.model(X_train)\n",
    "        loss = loss_function(pred, y_train)\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()  \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "<img src=\"./imgs/div.png\" width=\"100%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## 3.3 Bauen eines Ensembles\n",
    "\n",
    "Bisher unterscheided sich unsere Herangehensweise nicht von dem herkömmlichen Training eines Neuronalen Netzwerks - dennoch ist nicht mehr viel zu tun, um eine <span style=\"color:#179c80\"><b>Unsicherheitsschätzung</b></span> zu berechnen. Die Idee besteht nun in der Definition von <span style=\"color:#db8642\">T</span> Netzwerken und dem <span style=\"color:#db8642\">separaten</span> Training dieser Modelle. Anschließend kann <span style=\"color:#179c80\"><b>Mittelwert</b></span> und <span style=\"color:#179c80\"><b>Varianz</b></span> über die Vorhersagen dieser T Modelle berechnet werden. Der <span style=\"color:#179c80\"><b>Mittelwert</b></span> entspricht dabei der zusammengeführten <span style=\"color:#db8642\">Modellvorhersage</span> - die <span style=\"color:#179c80\"><b>Varianz</b></span> gibt Aufschluss über die <span style=\"color:#db8642\">Unsicherheit</span>. \n",
    "\n",
    "### Training\n",
    "<div class=\"alert alert-block alert-info\"  style=\"border-color:white\">\n",
    "    <b>Aufgabe</b>: Legen Sie <em>T</em> Modelle der Klasse <em>SLP</em> in der Liste <em>self.models</em> an und trainieren Sie jedes Modell separat durch den Aufruf der zuvor implementierten Methode. Achten Sie dabei darauf, die notwendigen Argumente zu übergeben. Hierfür vervollständigen Sie bitte die Methode <em>generate_and_train</em>.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"background-color:#f2decc\n",
    ";border-color:white\">\n",
    "    <b>Wichtige Klassenattribute</b>: \n",
    "    <ul>\n",
    "        <li> <em>self.T</em>: Anzahl der Modell (SLP) im Ensemble </li>\n",
    "        <li> <em>self.epochs</em>: Anzahl der Epochen </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\" style=\"border-color:white\">\n",
    "    <b>Wichtig!</b>: Bei Änderungen der <em>SLP</em> Klasse, führen sie die entsprechende Zelle neu aus. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Definition der Ensemble Klasse [Keine Änderung notwendig]\n",
    "class Ensembles():\n",
    "    def __init__(self, hidden, input_dim):\n",
    "\n",
    "        self.hidden = hidden\n",
    "        self.input_dim = input_dim\n",
    "        self.models = []\n",
    "        self.X, self.Y = None, None\n",
    "    \n",
    "    def load_data_and_params(self):\n",
    "        self.X, self.Y, _, _ = create_data(dataset=\"dataset_synthetic_regression\", feature_range=None, data_size=100,\n",
    "                                xrange=[range_slider.value[0], range_slider.value[1]])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.Y, test_size=0.1, shuffle=True, random_state=1)\n",
    "        X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float()\n",
    "        X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        self.T = int(dr.value)\n",
    "        self.epochs = int(slide_epochs.value)\n",
    "        return X_train, X_test, y_train, y_test, self.epochs, self.T \n",
    "    \n",
    "    def plot(self, obj):\n",
    "        try:\n",
    "            value = get_toggle_value(toggle, int(dr.value))\n",
    "        except:\n",
    "            pass\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            plot_deep_ensembles(self, self.X, self.Y, lambda u:u**3, [0], n=int(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Ensembles\n",
    "def generate_and_train(self):\n",
    "        X_train, X_test, y_train, y_test, self.epochs, self.T = self.load_data_and_params()\n",
    "        print(f\"\\nTraining of {self.T} models - each with {self.epochs} Epochs\")\n",
    "        \n",
    "        #self.models = [...]\n",
    "        \n",
    "        for i in tqdm.notebook.tqdm(range(self.T)):\n",
    "            #self.models[i]. ...\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### <div class=\"alert alert-block alert-success\" style=\"background-color:#b6dad2;color:#179c80;border-color:white\"> <b>Lösung</b> <small style=\"color:#179c80\">(Klicken auf den Pfeil um die Lösung aufzuklappen)</small></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Ensembles\n",
    "def generate_and_train(self):\n",
    "    X_train, X_test, y_train, y_test, self.epochs, self.T = self.load_data_and_params()\n",
    "    print(f\"\\nTraining of {self.T} models - each with {self.epochs} Epochs\")\n",
    "\n",
    "    self.models = [SLP() for _ in range(self.T)]\n",
    "\n",
    "    for i in tqdm.notebook.tqdm(range(self.T)):\n",
    "        self.models[i].train(X_train, y_train, self.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluierung\n",
    "<div class=\"alert alert-block alert-info\"  style=\"border-color:white\">\n",
    "    <b>Aufgabe</b>: Iterieren Sie über die Modelle in <em>self.models</em> und weisen die Modellvorhersage für die Testdaten dem entsprechendem Eintrag im Array <em>preds</em> zu. Vor dieser Zuweisung konvertieren Sie bitte über <em>.detach().numpy().flatten()</em> die Vorhersage zu einem flachen numpy Array. Anschließend berechnen Sie Mittelwert und Varianz über die Vorhersagen pro Testpunkt.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"background-color:#f2decc\n",
    ";border-color:white\">\n",
    "    <b>Hilfreiche Funktionen</b>: \n",
    "    <ul>\n",
    "        <li> <em>.detach().numpy().flatten()</em>: Konvertierung der Modellvorhersagen von Tensor zur Numpy Array </li>\n",
    "        <li> <em>np.mean(a, axis)</em>: axis=0 für Mittelwert über Werte in gleichen Spalten - axis=1 für Mittelwert über Werte in gleichen Reihen </li>\n",
    "        <li> <em>np.var(a, axis)</em>: axis=0 für Varianz über Werte in gleichen Spalten - axis=1 für Varianz über Werte in gleichen Reihen </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\" style=\"border-color:white\">\n",
    "    <b>Wichtig!</b>: Bei Änderungen der <em>SLP</em> Klasse, führen sie die entsprechende Zelle neu aus. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Ensembles\n",
    "def predict(self, X_test):\n",
    "    preds = np.zeros((self.T, X_test.size()[0]))\n",
    "    mu, var = 0, 0\n",
    "    \n",
    "    for i in range(len(self.models)):\n",
    "        #preds[i] = ...\n",
    "        pass\n",
    "\n",
    "    #mu = ...\n",
    "    #var = ...\n",
    "    return mu, var, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### <div class=\"alert alert-block alert-success\" style=\"background-color:#b6dad2;color:#179c80;border-color:white\"> <b>Lösung</b> <small style=\"color:#179c80\">(Klicken auf den Pfeil um die Lösung aufzuklappen)</small></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Ensembles\n",
    "def predict(self, X_test):\n",
    "    preds = np.zeros((self.T, X_test.size()[0]))\n",
    "    mu, var = 0, 0\n",
    "    \n",
    "    for i in range(len(self.models)):\n",
    "        preds[i] = self.models[i](X_test).detach().numpy().flatten()\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    mu = np.mean(preds, axis=0)\n",
    "    var = np.var(preds, axis=0)\n",
    "    return mu, var, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "<img src=\"./imgs/div.png\" width=\"100%\" /> \n",
    "\n",
    "### Visualisierung\n",
    "\n",
    "Nachfolgende grafische Benutzeroberfläche <span style=\"color:#179c80\"><b>kombiniert</b></span> alle umgesetzten Methoden und erlaubt die Visualisierung des Ergebnisses <span style=\"color:#db8642\">unter Berücksichtigung</span> einer unterschiedlichen Anzahl an Modellen. Gerne können Sie mit der Anzahl der <span style=\"color:#179c80\"><b>Modelle</b></span> und <span style=\"color:#179c80\"><b>Epochen</b></span> und den <span style=\"color:#179c80\"><b>Grenzen</b></span> der Datenbereiche <span style=\"color:#db8642\">experimentieren</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Starten der GUI [Keine Änderung notwendig]\n",
    "\n",
    "toggle = widgets.ToggleButtons(\n",
    "    options=[\"Eins\", \"Zwei\",\"Drei\", \"Alle\"],\n",
    "    description='Modellanzahl in Darstellung:',\n",
    "    layout = Layout(width=\"auto\"),\n",
    "    disabled=True,\n",
    "    button_style='',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "dr = widgets.Dropdown(\n",
    "    options=['3', '5', '10'],\n",
    "    value='5',\n",
    "    disabled=False, layout=Layout(width=\"100px\"),\n",
    "    description='Modelle: ',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "slide_epochs = widgets.IntSlider(value=80, min=40, max=200, step=20,\n",
    "                               layout=Layout(width=\"250px\"),\n",
    "                               description='Epochen: ', width=80,\n",
    "    style= {'description_width': 'initial'})\n",
    "\n",
    "range_slider = widgets.IntRangeSlider(\n",
    "    value=[-3., +3.],\n",
    "    min=-5., max=+5., step=1,\n",
    "    description='Daten Limits:',\n",
    "    layout=Layout(width=\"300px\"),\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "btn = widgets.Button(description=\"Training\", layout=Layout(width=\"100px\"),)\n",
    "btn2 = widgets.Button(description=\"Reset\", layout=Layout(width=\"100px\"),)\n",
    "out = widgets.Output()\n",
    "de = Ensembles(hidden=50, input_dim=1)\n",
    "toggle.observe(de.plot, names=\"value\")\n",
    "\n",
    "def train(btn):\n",
    "    torch.manual_seed(40)\n",
    "    np.random.seed(40)       \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        dr.disabled=True\n",
    "        slide_epochs.disabled=True\n",
    "        range_slider.disabled=True\n",
    "        btn.disabled=True\n",
    "        toggle.disabled=True\n",
    "\n",
    "        de.generate_and_train()\n",
    "        #y_pred, y_cov, raw = model.predict(X_test)    \n",
    "        de.plot(get_toggle_value(toggle, int(dr.value)))\n",
    "        toggle.disabled=False\n",
    "\n",
    "\n",
    "def reset(obj):\n",
    "     with out:\n",
    "        dr.disabled=False\n",
    "        slide_epochs.disabled=False\n",
    "        range_slider.disabled=False\n",
    "        btn.disabled=False\n",
    "        toggle.disabled=True\n",
    "        clear_output()\n",
    "btn.on_click(train)\n",
    "btn2.on_click(reset)\n",
    "# start gui\n",
    "widgets.VBox([widgets.HBox([dr, widgets.Label(layout=Layout(width=\"20px\")), slide_epochs,widgets.Label(layout=Layout(width=\"10px\")),range_slider, btn, btn2]),toggle, widgets.HBox([out])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
